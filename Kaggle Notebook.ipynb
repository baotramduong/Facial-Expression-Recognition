{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, plot_confusion_matrix\nfrom sklearn.metrics import auc,roc_curve,roc_auc_score\n\nimport tensorflow as tf\nprint(\"Tensorflow version:\", tf.__version__)\n\nimport tensorflow.keras as keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, array_to_img, img_to_array\nfrom tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\nfrom tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.utils import plot_model\n\nfrom IPython.display import SVG, Image\n\n!pip install livelossplot\nfrom livelossplot.tf_keras import PlotLossesCallback\n\nimport warnings\nwarnings.filterwarnings(action='ignore', category=FutureWarning)","metadata":{"id":"wvGxjjeV-9Ls","outputId":"3c873904-9ac3-471c-81a8-bcf71772cfc6","execution":{"iopub.status.busy":"2021-09-28T06:48:55.805491Z","iopub.execute_input":"2021-09-28T06:48:55.806312Z","iopub.status.idle":"2021-09-28T06:49:02.766924Z","shell.execute_reply.started":"2021-09-28T06:48:55.806260Z","shell.execute_reply":"2021-09-28T06:49:02.766004Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{"id":"Tg1p132CQpwl"}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename));","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:02.770948Z","iopub.execute_input":"2021-09-28T06:49:02.771189Z","iopub.status.idle":"2021-09-28T06:49:02.779356Z","shell.execute_reply.started":"2021-09-28T06:49:02.771148Z","shell.execute_reply":"2021-09-28T06:49:02.778406Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"#define path to the data directory\nbase_dir = '/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/'","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:02.781386Z","iopub.execute_input":"2021-09-28T06:49:02.781742Z","iopub.status.idle":"2021-09-28T06:49:02.787994Z","shell.execute_reply.started":"2021-09-28T06:49:02.781697Z","shell.execute_reply":"2021-09-28T06:49:02.787196Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"os.listdir(base_dir)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:02.790492Z","iopub.execute_input":"2021-09-28T06:49:02.791199Z","iopub.status.idle":"2021-09-28T06:49:02.798699Z","shell.execute_reply.started":"2021-09-28T06:49:02.791147Z","shell.execute_reply":"2021-09-28T06:49:02.797631Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"#read the entire dataset\ndf = pd.read_csv(base_dir+'icml_face_data.csv')\ndf.columns = ['emotion', 'Usage', 'pixels']\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:02.800544Z","iopub.execute_input":"2021-09-28T06:49:02.800907Z","iopub.status.idle":"2021-09-28T06:49:05.438964Z","shell.execute_reply.started":"2021-09-28T06:49:02.800873Z","shell.execute_reply":"2021-09-28T06:49:05.438150Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:05.440444Z","iopub.execute_input":"2021-09-28T06:49:05.440710Z","iopub.status.idle":"2021-09-28T06:49:05.461934Z","shell.execute_reply.started":"2021-09-28T06:49:05.440675Z","shell.execute_reply":"2021-09-28T06:49:05.461148Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"df['emotion'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:05.463318Z","iopub.execute_input":"2021-09-28T06:49:05.463581Z","iopub.status.idle":"2021-09-28T06:49:05.470971Z","shell.execute_reply.started":"2021-09-28T06:49:05.463546Z","shell.execute_reply":"2021-09-28T06:49:05.470242Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"df['Usage'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:05.472482Z","iopub.execute_input":"2021-09-28T06:49:05.472878Z","iopub.status.idle":"2021-09-28T06:49:05.488592Z","shell.execute_reply.started":"2021-09-28T06:49:05.472843Z","shell.execute_reply":"2021-09-28T06:49:05.487781Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"#read train data\ntrain = pd.read_csv(base_dir+'train.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:05.490065Z","iopub.execute_input":"2021-09-28T06:49:05.490466Z","iopub.status.idle":"2021-09-28T06:49:07.411601Z","shell.execute_reply.started":"2021-09-28T06:49:05.490430Z","shell.execute_reply":"2021-09-28T06:49:07.410739Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"#read test data\ntest = pd.read_csv(base_dir+'test.csv')\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:07.433304Z","iopub.execute_input":"2021-09-28T06:49:07.433735Z","iopub.status.idle":"2021-09-28T06:49:07.928377Z","shell.execute_reply.started":"2021-09-28T06:49:07.433700Z","shell.execute_reply":"2021-09-28T06:49:07.927491Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:07.944973Z","iopub.execute_input":"2021-09-28T06:49:07.945922Z","iopub.status.idle":"2021-09-28T06:49:07.952917Z","shell.execute_reply.started":"2021-09-28T06:49:07.945764Z","shell.execute_reply":"2021-09-28T06:49:07.951925Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(30,8))\n\nsns.countplot(data = df[df['Usage']=='Training'], x='emotion', ax=ax1, palette='Spectral').set_title('Training')\nax1.set_xticklabels(emotions.values())\n\nsns.countplot(data = df[df['Usage']=='PublicTest'], x='emotion', ax=ax2, palette='Spectral').set_title('Testing')\nax2.set_xticklabels(emotions.values())\n\nsns.countplot(data = df[df['Usage']=='PrivateTest'], x='emotion', ax=ax3, palette='Spectral').set_title('Validation')\nax3.set_xticklabels(emotions.values())","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:07.954476Z","iopub.execute_input":"2021-09-28T06:49:07.954901Z","iopub.status.idle":"2021-09-28T06:49:08.463261Z","shell.execute_reply.started":"2021-09-28T06:49:07.954863Z","shell.execute_reply":"2021-09-28T06:49:08.462568Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(1, (20, 20))\n\nk = 0\nfor label in sorted(df['emotion'].unique()):\n    for j in range(7):\n        px = df[df['emotion']==label].pixels.iloc[k]\n        px = np.array(px.split(' ')).reshape(48, 48).astype('float32')\n\n        k += 1\n        ax = plt.subplot(7, 7, k)\n        ax.imshow(px, cmap='gray')\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(emotions[label])\n        plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:08.464533Z","iopub.execute_input":"2021-09-28T06:49:08.464798Z","iopub.status.idle":"2021-09-28T06:49:16.235432Z","shell.execute_reply.started":"2021-09-28T06:49:08.464764Z","shell.execute_reply":"2021-09-28T06:49:16.234457Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"## Prepare Train & Test Set Inputs\n### Train Set","metadata":{}},{"cell_type":"code","source":"train_data = df[df['Usage']=='Training']\ntrain_data.drop(columns='Usage', inplace=True)\ntrain_data.head()","metadata":{"id":"D3RHxw7nQpwm","execution":{"iopub.status.busy":"2021-09-28T06:49:16.236803Z","iopub.execute_input":"2021-09-28T06:49:16.237078Z","iopub.status.idle":"2021-09-28T06:49:16.258902Z","shell.execute_reply.started":"2021-09-28T06:49:16.237043Z","shell.execute_reply":"2021-09-28T06:49:16.258110Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"train_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:16.260124Z","iopub.execute_input":"2021-09-28T06:49:16.260422Z","iopub.status.idle":"2021-09-28T06:49:16.271933Z","shell.execute_reply.started":"2021-09-28T06:49:16.260388Z","shell.execute_reply":"2021-09-28T06:49:16.270998Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:16.273300Z","iopub.execute_input":"2021-09-28T06:49:16.273701Z","iopub.status.idle":"2021-09-28T06:49:16.290912Z","shell.execute_reply.started":"2021-09-28T06:49:16.273667Z","shell.execute_reply":"2021-09-28T06:49:16.289964Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"train_data['pixels'][0]","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:16.292352Z","iopub.execute_input":"2021-09-28T06:49:16.292656Z","iopub.status.idle":"2021-09-28T06:49:16.299829Z","shell.execute_reply.started":"2021-09-28T06:49:16.292622Z","shell.execute_reply":"2021-09-28T06:49:16.298947Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"def prepare_data(data):\n    image_array = np.zeros(shape=(len(data), 48, 48, 1))\n    image_label = np.array(list(map(int, data['emotion'])))\n\n    for i, row in enumerate(data.index):\n        image = np.fromstring(data.loc[row, 'pixels'], dtype=int, sep=' ')\n        image = np.reshape(image, (48, 48)) \n        image_array[i, :, :, 0] = image / 255\n\n    return image_array, image_label","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:16.301380Z","iopub.execute_input":"2021-09-28T06:49:16.301865Z","iopub.status.idle":"2021-09-28T06:49:16.309867Z","shell.execute_reply.started":"2021-09-28T06:49:16.301832Z","shell.execute_reply":"2021-09-28T06:49:16.308948Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = prepare_data(train_data)\nprint(X_train.shape, y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:16.311252Z","iopub.execute_input":"2021-09-28T06:49:16.311563Z","iopub.status.idle":"2021-09-28T06:49:19.581337Z","shell.execute_reply.started":"2021-09-28T06:49:16.311529Z","shell.execute_reply":"2021-09-28T06:49:19.580556Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:19.582477Z","iopub.execute_input":"2021-09-28T06:49:19.583148Z","iopub.status.idle":"2021-09-28T06:49:19.596213Z","shell.execute_reply.started":"2021-09-28T06:49:19.583110Z","shell.execute_reply":"2021-09-28T06:49:19.595561Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:19.597427Z","iopub.execute_input":"2021-09-28T06:49:19.597682Z","iopub.status.idle":"2021-09-28T06:49:19.603240Z","shell.execute_reply.started":"2021-09-28T06:49:19.597650Z","shell.execute_reply":"2021-09-28T06:49:19.602356Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"### Test Set","metadata":{}},{"cell_type":"code","source":"test_data = df[df['Usage']!='Training']\ntest_data.drop(columns='Usage', inplace=True)\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:19.604669Z","iopub.execute_input":"2021-09-28T06:49:19.605015Z","iopub.status.idle":"2021-09-28T06:49:19.626059Z","shell.execute_reply.started":"2021-09-28T06:49:19.604959Z","shell.execute_reply":"2021-09-28T06:49:19.625408Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"X_test, y_test = prepare_data(test_data)\nprint(X_test.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:19.627198Z","iopub.execute_input":"2021-09-28T06:49:19.627671Z","iopub.status.idle":"2021-09-28T06:49:20.452264Z","shell.execute_reply.started":"2021-09-28T06:49:19.627637Z","shell.execute_reply":"2021-09-28T06:49:20.451498Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"### Train Test Split","metadata":{}},{"cell_type":"code","source":"#split train set into training and validation set\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n                                                  test_size=0.2, \n                                                  random_state=121,\n                                                  shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:20.453406Z","iopub.execute_input":"2021-09-28T06:49:20.454099Z","iopub.status.idle":"2021-09-28T06:49:20.616921Z","shell.execute_reply.started":"2021-09-28T06:49:20.454061Z","shell.execute_reply":"2021-09-28T06:49:20.616177Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"print('X_train', X_train.shape)\nprint('X_test', X_test.shape)\nprint('X_val', X_val.shape)\n\nprint('y_train', y_train.shape)\nprint('y_test', y_test.shape)\nprint('y_val', y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:20.618081Z","iopub.execute_input":"2021-09-28T06:49:20.618530Z","iopub.status.idle":"2021-09-28T06:49:20.627509Z","shell.execute_reply.started":"2021-09-28T06:49:20.618492Z","shell.execute_reply":"2021-09-28T06:49:20.626452Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"### Prepare Labels","metadata":{}},{"cell_type":"code","source":"y_train = keras.utils.to_categorical(y_train)\ny_test = keras.utils.to_categorical(y_test)\ny_val = keras.utils.to_categorical(y_val)\n\nprint('y_train', y_train.shape)\nprint('y_test', y_test.shape)\nprint('y_val', y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:20.632838Z","iopub.execute_input":"2021-09-28T06:49:20.633023Z","iopub.status.idle":"2021-09-28T06:49:20.640800Z","shell.execute_reply.started":"2021-09-28T06:49:20.633002Z","shell.execute_reply":"2021-09-28T06:49:20.640123Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:20.641911Z","iopub.execute_input":"2021-09-28T06:49:20.642583Z","iopub.status.idle":"2021-09-28T06:49:20.650104Z","shell.execute_reply.started":"2021-09-28T06:49:20.642546Z","shell.execute_reply":"2021-09-28T06:49:20.649328Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"def plot_examples(label):\n    fig, axs = plt.subplots(1, 5, figsize=(20, 8))\n    fig.subplots_adjust(hspace = .2, wspace=.2)\n    axs = axs.ravel()\n    for i in range(5):\n        idx = train_data[train_data['emotion']==label].index[i]\n        axs[i].imshow(X_train[idx][:,:,0], cmap='gray')\n        axs[i].set_title(emotions[label])\n        axs[i].set_xticklabels([])\n        axs[i].set_yticklabels([])","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:20.651240Z","iopub.execute_input":"2021-09-28T06:49:20.652011Z","iopub.status.idle":"2021-09-28T06:49:20.659800Z","shell.execute_reply.started":"2021-09-28T06:49:20.651977Z","shell.execute_reply":"2021-09-28T06:49:20.659120Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"plot_examples(label=0)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:20.661135Z","iopub.execute_input":"2021-09-28T06:49:20.661507Z","iopub.status.idle":"2021-09-28T06:49:21.176827Z","shell.execute_reply.started":"2021-09-28T06:49:20.661473Z","shell.execute_reply":"2021-09-28T06:49:21.176110Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"plot_examples(label=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:21.178355Z","iopub.execute_input":"2021-09-28T06:49:21.178629Z","iopub.status.idle":"2021-09-28T06:49:21.692589Z","shell.execute_reply.started":"2021-09-28T06:49:21.178593Z","shell.execute_reply":"2021-09-28T06:49:21.691892Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"plot_examples(label=2)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:21.693890Z","iopub.execute_input":"2021-09-28T06:49:21.694302Z","iopub.status.idle":"2021-09-28T06:49:22.209148Z","shell.execute_reply.started":"2021-09-28T06:49:21.694262Z","shell.execute_reply":"2021-09-28T06:49:22.208462Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"plot_examples(label=3)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:22.210492Z","iopub.execute_input":"2021-09-28T06:49:22.210745Z","iopub.status.idle":"2021-09-28T06:49:22.723688Z","shell.execute_reply.started":"2021-09-28T06:49:22.210710Z","shell.execute_reply":"2021-09-28T06:49:22.722999Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"plot_examples(label=4)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:22.724963Z","iopub.execute_input":"2021-09-28T06:49:22.725222Z","iopub.status.idle":"2021-09-28T06:49:23.479323Z","shell.execute_reply.started":"2021-09-28T06:49:22.725188Z","shell.execute_reply":"2021-09-28T06:49:23.478630Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"plot_examples(label=5)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:23.480689Z","iopub.execute_input":"2021-09-28T06:49:23.480944Z","iopub.status.idle":"2021-09-28T06:49:24.009108Z","shell.execute_reply.started":"2021-09-28T06:49:23.480911Z","shell.execute_reply":"2021-09-28T06:49:24.008333Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"plot_examples(label=6)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:49:24.010227Z","iopub.execute_input":"2021-09-28T06:49:24.010923Z","iopub.status.idle":"2021-09-28T06:49:24.525087Z","shell.execute_reply.started":"2021-09-28T06:49:24.010877Z","shell.execute_reply":"2021-09-28T06:49:24.524399Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"## Data Loader and Data Augmentation","metadata":{"id":"6OGl90WwQpwm"}},{"cell_type":"code","source":"img_size = 48\nbatch_size = 32\n\n#use Image Data Generator to perform this task\n#train set\ndatagen = ImageDataGenerator(rotation_range=25, \n                             width_shift_range=0.1,\n                             height_shift_range=0.1, \n                             shear_range=0.2, \n                             zoom_range=0.2,\n                             horizontal_flip=True)\n\ndatagen.fit(X_train)\ndatagen.fit(X_val)","metadata":{"id":"eiLYEHfuWt4N","execution":{"iopub.status.busy":"2021-09-28T06:49:24.526134Z","iopub.execute_input":"2021-09-28T06:49:24.526393Z","iopub.status.idle":"2021-09-28T06:49:24.726201Z","shell.execute_reply.started":"2021-09-28T06:49:24.526359Z","shell.execute_reply":"2021-09-28T06:49:24.725443Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"## Build Model","metadata":{"id":"qxPfLAs-Qpwo"}},{"cell_type":"code","source":"model = Sequential()\n\n#1st conv\nmodel.add(Conv2D(64, (3,3), padding='same', input_shape=(48,48,1))) #1 is for grayscale\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#2nd conv\nmodel.add(Conv2D(128, (5,5), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#3rd conv\nmodel.add(Conv2D(512, (3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#4th conv\nmodel.add(Conv2D(512, (3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(7, activation='softmax'))","metadata":{"id":"uVJJqiPbQpwo","execution":{"iopub.status.busy":"2021-09-28T06:49:24.727339Z","iopub.execute_input":"2021-09-28T06:49:24.728118Z","iopub.status.idle":"2021-09-28T06:49:24.939921Z","shell.execute_reply.started":"2021-09-28T06:49:24.728080Z","shell.execute_reply":"2021-09-28T06:49:24.938571Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"#compile\nmodel.compile(optimizer=keras.optimizers.Adam(learning_rate = 1e-5),\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])","metadata":{"id":"isuc5IcUQpwp","execution":{"iopub.status.busy":"2021-09-28T06:49:24.941583Z","iopub.execute_input":"2021-09-28T06:49:24.942137Z","iopub.status.idle":"2021-09-28T06:49:24.960852Z","shell.execute_reply.started":"2021-09-28T06:49:24.942100Z","shell.execute_reply":"2021-09-28T06:49:24.957269Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"id":"PB1zZcr6Qpwq","execution":{"iopub.status.busy":"2021-09-28T06:49:24.962058Z","iopub.execute_input":"2021-09-28T06:49:24.962354Z","iopub.status.idle":"2021-09-28T06:49:24.999096Z","shell.execute_reply.started":"2021-09-28T06:49:24.962322Z","shell.execute_reply":"2021-09-28T06:49:24.998320Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\n\n#plot\nplot_model(model, to_file = 'model_plot.png', show_shapes = True, show_layer_names = True)","metadata":{"id":"lY8ghrg7YHZ0","execution":{"iopub.status.busy":"2021-09-28T06:49:25.002614Z","iopub.execute_input":"2021-09-28T06:49:25.004569Z","iopub.status.idle":"2021-09-28T06:49:25.587517Z","shell.execute_reply.started":"2021-09-28T06:49:25.004528Z","shell.execute_reply":"2021-09-28T06:49:25.586798Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"markdown","source":"## Train Model","metadata":{"id":"WSpOKdKsQpwq"}},{"cell_type":"code","source":"epochs = 10\nsteps_per_epoch = len(X_train)//batch_size\nvalidation_steps = len(X_val)//batch_size\n\ncheckpoint = ModelCheckpoint('model_weights.h5',\n                             monitor='val_accuracy',\n                             save_weights_only=True,\n                             mode='max',\n                             verbose=1)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.1,\n                              patience=2,\n                              min_lr=0.00001,\n                              mode='auto')\n\nearlystop = EarlyStopping(monitor='val_accuracy',\n                          patience=5,\n                          mode='auto',\n                          verbose=1)\n\ncallbacks = [PlotLossesCallback(), earlystop, checkpoint, reduce_lr]","metadata":{"id":"N2vaREgMQpwq","execution":{"iopub.status.busy":"2021-09-28T06:49:25.589003Z","iopub.execute_input":"2021-09-28T06:49:25.589628Z","iopub.status.idle":"2021-09-28T06:49:25.598724Z","shell.execute_reply.started":"2021-09-28T06:49:25.589581Z","shell.execute_reply":"2021-09-28T06:49:25.597513Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train,\n                   steps_per_epoch=steps_per_epoch,\n                   epochs=epochs,\n                   validation_data=(X_val, y_val),\n                   validation_steps=validation_steps,\n                   callbacks=callbacks)","metadata":{"id":"aqZE_nD0Qpwr","execution":{"iopub.status.busy":"2021-09-28T06:49:25.600198Z","iopub.execute_input":"2021-09-28T06:49:25.600856Z","iopub.status.idle":"2021-09-28T06:50:58.794728Z","shell.execute_reply.started":"2021-09-28T06:49:25.600819Z","shell.execute_reply":"2021-09-28T06:50:58.793876Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate Model ","metadata":{"id":"aVrjqCeKQpwr"}},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\nfig.set_size_inches(20, 8)\n\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(train_acc) + 1)\n\nax[0].plot(epochs , train_acc , 'g-o' , label = 'Training Accuracy')\nax[0].plot(epochs , val_acc , 'y-o' , label = 'Validation Accuracy')\nax[0].set_title('Model Training & Validation Accuracy')\nax[0].legend(loc = 'lower right')\nax[0].set_xlabel(\"Epochs\")\nax[0].set_ylabel(\"Accuracy\")\n\nax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\nax[1].plot(epochs , val_loss , 'y-o' , label = 'Validation Loss')\nax[1].set_title('Model Training & Validation & Loss')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nax[1].set_ylabel(\"Loss\")\n\nplt.show()","metadata":{"id":"2aF_3ka3V4Pt","execution":{"iopub.status.busy":"2021-09-28T06:50:58.796282Z","iopub.execute_input":"2021-09-28T06:50:58.796544Z","iopub.status.idle":"2021-09-28T06:50:59.154184Z","shell.execute_reply.started":"2021-09-28T06:50:58.796511Z","shell.execute_reply":"2021-09-28T06:50:59.152406Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"print('Train accuracy & loss:', model.evaluate(X_train, y_train))\nprint('\\n')\nprint('Test accuracy & loss:', model.evaluate(X_test, y_test))","metadata":{"id":"UbROrWHOV7IH","execution":{"iopub.status.busy":"2021-09-28T06:51:07.895032Z","iopub.execute_input":"2021-09-28T06:51:07.895336Z","iopub.status.idle":"2021-09-28T06:51:13.570206Z","shell.execute_reply.started":"2021-09-28T06:51:07.895305Z","shell.execute_reply":"2021-09-28T06:51:13.569425Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"#make prediction\nyhat_test = np.argmax(model.predict(X_test), axis=1)\nyhat_test","metadata":{"id":"bbGgOWUgV9Uv","execution":{"iopub.status.busy":"2021-09-28T06:51:14.823629Z","iopub.execute_input":"2021-09-28T06:51:14.824192Z","iopub.status.idle":"2021-09-28T06:51:15.809441Z","shell.execute_reply.started":"2021-09-28T06:51:14.824138Z","shell.execute_reply":"2021-09-28T06:51:15.808745Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"y_test = np.argmax(y_test, axis=1)\ny_test","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:51:16.367878Z","iopub.execute_input":"2021-09-28T06:51:16.368411Z","iopub.status.idle":"2021-09-28T06:51:16.373921Z","shell.execute_reply.started":"2021-09-28T06:51:16.368369Z","shell.execute_reply":"2021-09-28T06:51:16.373226Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"from mlxtend.plotting import plot_confusion_matrix\n\n#get confusion matrix\ncm = confusion_matrix(y_test, yhat_test)\nprint(cm)\n\nfig, ax = plot_confusion_matrix(conf_mat=cm,\n                                show_normed=True,\n                                show_absolute=False,\n                                class_names=emotions.values(),\n                                figsize=(8, 8))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:51:19.899859Z","iopub.execute_input":"2021-09-28T06:51:19.900549Z","iopub.status.idle":"2021-09-28T06:51:20.353986Z","shell.execute_reply.started":"2021-09-28T06:51:19.900506Z","shell.execute_reply":"2021-09-28T06:51:20.353146Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"#get classification report\nprint(classification_report(y_test, yhat_test, target_names=emotions.values()))","metadata":{"id":"CySOfMCdWUk2","execution":{"iopub.status.busy":"2021-09-28T06:51:22.082971Z","iopub.execute_input":"2021-09-28T06:51:22.083584Z","iopub.status.idle":"2021-09-28T06:51:22.108201Z","shell.execute_reply.started":"2021-09-28T06:51:22.083541Z","shell.execute_reply":"2021-09-28T06:51:22.107433Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"model_json = model.to_json()\nwith open('model.json','w') as json_file:\n    json_file.write(model_json)\n    \nmodel.save('final_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:51:23.576073Z","iopub.execute_input":"2021-09-28T06:51:23.576955Z","iopub.status.idle":"2021-09-28T06:51:23.720006Z","shell.execute_reply.started":"2021-09-28T06:51:23.576903Z","shell.execute_reply":"2021-09-28T06:51:23.719244Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"markdown","source":"## Make Prediction","metadata":{"id":"5a3ddKtGa_fy"}},{"cell_type":"code","source":"emotions_mapper = {0: 'angry',\n                   1: 'disgust',\n                   2: 'fear',\n                   3: 'happy',\n                   4: 'sad',\n                   5: 'surprise',\n                   6: 'neutral'}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_angry_imgs = np.random.choice(np.where(y_test==0))\n\n#angry\nplt.subplot(1, 5, i+1)\nsample_img = X_test[angryidx,:,:,0]\nplt.imshow(sample_img, cmap='gray')\nplt.set_xticks([])\nplt.set_yticks([])\nplt.set_title(f\"true:angry, pred:{emotions_mapper[model.predict_classes(sample_img.reshape(1,48,48,1))[0]]}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:54:09.846532Z","iopub.execute_input":"2021-09-28T06:54:09.847241Z","iopub.status.idle":"2021-09-28T06:54:09.891613Z","shell.execute_reply.started":"2021-09-28T06:54:09.847199Z","shell.execute_reply":"2021-09-28T06:54:09.890019Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"np.random.seed(21)\nrandom_angry_imgs = np.random.choice(np.where(y_test[:, 1]==0)[0], size=5)\nrandom_disgust_imgs = np.random.choice(np.where(y_test[:, 1]==1)[0], size=5)\nrandom_fear_imgs = np.random.choice(np.where(y_test[:, 1]==2)[0], size=5)\nrandom_happy_imgs = np.random.choice(np.where(y_test[:, 1]==3)[0], size=5)\nrandom_sad_imgs = np.random.choice(np.where(y_test[:, 1]==4)[0], size=5)\nrandom_surprise_imgs = np.random.choice(np.where(y_test[:, 5]==1)[0], size=5)\nrandom_neutral_imgs = np.random.choice(np.where(y_test[:, 6]==1)[0], size=5)\n\nfig = plt.figure(figsize=(30, 30))\n\nfor i, (angryidx, disgustidx, fearidx, \n        happyidx, sadidx, surpriseidx, neuidx) in enumerate(zip(random_angry_imgs, random_disgust_imgs, random_fear_imgs,\n                                                                random_happy_imgs, random_sad_imgs, random_surprise_imgs, \n                                                                random_neutral_imgs)):\n        #angry\n        ax1 = plt.subplot(1, 5, i+1)\n        sample_img = X_test[angryidx,:,:,0]\n        ax1.imshow(sample_img, cmap='gray')\n        ax1.set_xticks([])\n        ax1.set_yticks([])\n        ax1.set_title(f\"true:angry, pred:{emotions_mapper[model.predict_classes(sample_img.reshape(1,48,48,1))[0]]}\")\n\n        #disgust\n        ax2 = plt.subplot(1, 5, i+1)\n        sample_img = X_test[disgustidx,:,:,0]\n        ax2.imshow(sample_img, cmap='gray')\n        ax2.set_xticks([])\n        ax2.set_yticks([])\n        ax2.set_title(f\"true:disgust, pred:{emotions_mapper[model.predict_classes(sample_img.reshape(1,48,48,1))[0]]}\")\n        \n        #fear\n        ax3 = plt.subplot(1, 5, i+1)\n        sample_img = X_test[fearidx,:,:,0]\n        ax3.imshow(sample_img, cmap='gray')\n        ax3.set_xticks([])\n        ax3.set_yticks([])\n        ax3.set_title(f\"true:fear, pred:{emotions_mapper[model.predict_classes(sample_img.reshape(1,48,48,1))[0]]}\")        \n        \n        #happy\n        ax4 = plt.subplot(1, 5, i+1)\n        sample_img = X_test[happyidx,:,:,0]\n        ax4.imshow(sample_img, cmap='gray')\n        ax4.set_xticks([])\n        ax4.set_yticks([])\n        ax4.set_title(f\"true:happy, pred:{emotions_mapper[model.predict_classes(sample_img.reshape(1,48,48,1))[0]]}\")        \n        \n        #sad\n        ax5 = plt.subplot(1, 5, i+1)\n        sample_img = X_test[sadidx,:,:,0]\n        ax5.imshow(sample_img, cmap='gray')\n        ax5.set_xticks([])\n        ax5.set_yticks([])\n        ax5.set_title(f\"true:sad, pred:{emotions_mapper[model.predict_classes(sample_img.reshape(1,48,48,1))[0]]}\")        \n        \n        #surprise\n        ax6 = plt.subplot(1, 5, i+1)\n        sample_img = X_test[surpriseidx,:,:,0]\n        ax6.imshow(sample_img, cmap='gray')\n        ax6.set_xticks([])\n        ax6.set_yticks([])\n        ax6.set_title(f\"true:surpise, pred:{emotions_mapper[model.predict_classes(sample_img.reshape(1,48,48,1))[0]]}\")        \n        \n        #neutral\n        ax7 = pyplot.subplot(1, 5, i+1)\n        sample_img = X_test[neuidx,:,:,0]\n        ax7.imshow(sample_img, cmap='gray')\n        ax7.set_xticks([])\n        ax7.set_yticks([])\n        ax7.set_title(f\"t:neut, p:{emotions_mapper[model.predict_classes(sample_img.reshape(1,48,48,1))[0]]}\")\n\n        plt.tight_layout()","metadata":{"id":"NCj2lBngbfuU","execution":{"iopub.status.busy":"2021-09-28T06:51:25.597265Z","iopub.execute_input":"2021-09-28T06:51:25.597592Z","iopub.status.idle":"2021-09-28T06:51:25.642712Z","shell.execute_reply.started":"2021-09-28T06:51:25.597559Z","shell.execute_reply":"2021-09-28T06:51:25.641567Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"markdown","source":"## FER","metadata":{"id":"_kgewYcIp9kU"}},{"cell_type":"code","source":"!pip install fer","metadata":{"id":"IgWOyucEp88W","outputId":"77ed89db-1a60-44d0-e79f-6340800d08a1","execution":{"iopub.status.busy":"2021-09-28T06:50:59.168377Z","iopub.status.idle":"2021-09-28T06:50:59.169238Z","shell.execute_reply.started":"2021-09-28T06:50:59.168979Z","shell.execute_reply":"2021-09-28T06:50:59.169002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20, 20))\n\nfor i in range(25):\n    ax = fig.add_subplot(1, 5, i + 1)    \n    image = np.random.choice(np.where(y_test[:, 1]==0)[0], size=5)\n    detector = FER()\n    detector.detect_emotions(img)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T06:50:59.170224Z","iopub.status.idle":"2021-09-28T06:50:59.170760Z","shell.execute_reply.started":"2021-09-28T06:50:59.170523Z","shell.execute_reply":"2021-09-28T06:50:59.170546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fer import FER\nimport cv2\n\nimg = cv2.imread(\"justin.jpg\")\ndetector = FER()\ndetector.detect_emotions(img)","metadata":{"id":"juZpbzfmqGJV","execution":{"iopub.status.busy":"2021-09-28T06:50:59.172043Z","iopub.status.idle":"2021-09-28T06:50:59.172889Z","shell.execute_reply.started":"2021-09-28T06:50:59.172628Z","shell.execute_reply":"2021-09-28T06:50:59.172653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Grad-CAM","metadata":{"id":"yk4p_LpXZEGd"}},{"cell_type":"code","source":"#https://github.com/gkeechin/vizgradcam/blob/main/gradcam.py\n\ndef VizGradCAM(model, image, interpolant=0.5, plot_results=True):\n\n    \"\"\"VizGradCAM - Displays GradCAM based on Keras / TensorFlow models\n    using the gradients from the last convolutional layer. This function\n    should work with all Keras Application listed here:\n    https://keras.io/api/applications/\n    Parameters:\n    model (keras.model): Compiled Model with Weights Loaded\n    image: Image to Perform Inference On\n    plot_results (boolean): True - Function Plots using PLT\n                            False - Returns Heatmap Array\n    Returns:\n    Heatmap Array?\n    \"\"\"\n    #sanity check\n    assert (interpolant > 0 and interpolant < 1), \"Heatmap Interpolation Must Be Between 0 - 1\"\n\n    #STEP 1: Preprocesss image and make prediction using our model\n    #input image\n    original_img = np.asarray(image, dtype = np.float32)\n    #expamd dimension and get batch size\n    img = np.expand_dims(original_img, axis=0)\n    #predict\n    prediction = model.predict(img)\n    #prediction index\n    prediction_idx = np.argmax(prediction)\n\n    #STEP 2: Create new model\n    #specify last convolutional layer\n    last_conv_layer = next(x for x in model.layers[::-1] if isinstance(x, K.layers.Conv2D))\n    target_layer = model.get_layer(last_conv_layer.name)\n\n    #compute gradient of top predicted class\n    with tf.GradientTape() as tape:\n        #create a model with original model inputs and the last conv_layer as the output\n        gradient_model = Model([model.inputs], [target_layer.output, model.output])\n        #pass the image through the base model and get the feature map  \n        conv2d_out, prediction = gradient_model(img)\n        #prediction loss\n        loss = prediction[:, prediction_idx]\n\n    #gradient() computes the gradient using operations recorded in context of this tape\n    gradients = tape.gradient(loss, conv2d_out)\n\n    #obtain the output from shape [1 x H x W x CHANNEL] -> [H x W x CHANNEL]\n    output = conv2d_out[0]\n\n    #obtain depthwise mean\n    weights = tf.reduce_mean(gradients[0], axis=(0, 1))\n\n\n    #create a 7x7 map for aggregation\n    activation_map = np.zeros(output.shape[0:2], dtype=np.float32)\n    #multiply weight for every layer\n    for idx, weight in enumerate(weights):\n        activation_map += weight * output[:, :, idx]\n    #resize to image size\n    activation_map = cv2.resize(activation_map.numpy(), \n                                (original_img.shape[1], \n                                 original_img.shape[0]))\n    #ensure no negative number\n    activation_map = np.maximum(activation_map, 0)\n    #convert class activation map to 0 - 255\n    activation_map = (activation_map - activation_map.min()) / (activation_map.max() - activation_map.min())\n    #rescale and convert the type to int\n    activation_map = np.uint8(255 * activation_map)\n\n\n    #convert to heatmap\n    heatmap = cv2.applyColorMap(activation_map, cv2.COLORMAP_JET)\n\n    #superimpose heatmap onto image\n    original_img = np.uint8((original_img - original_img.min()) / (original_img.max() - original_img.min()) * 255)\n    cvt_heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n    cvt_heatmap = img_to_array(cvt_heatmap)\n\n    #enlarge plot\n    plt.rcParams[\"figure.dpi\"] = 100\n\n    if plot_results == True:\n        plt.imshow(np.uint8(original_img * interpolant + cvt_heatmap * (1 - interpolant)))\n    else:\n        return cvt_heatmap","metadata":{"id":"A2iJNT8GZCib","execution":{"iopub.status.busy":"2021-09-28T06:50:59.174198Z","iopub.status.idle":"2021-09-28T06:50:59.174767Z","shell.execute_reply.started":"2021-09-28T06:50:59.174525Z","shell.execute_reply":"2021-09-28T06:50:59.174548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load image\ntest_img = cv2.imread(\"/train/4.jpg\")\n\n#apply function\nVizGradCAM(model, img_to_array(test_img), plot_results=True)","metadata":{"id":"5ZvQ17oRZHkO","execution":{"iopub.status.busy":"2021-09-28T06:50:59.175875Z","iopub.status.idle":"2021-09-28T06:50:59.176506Z","shell.execute_reply.started":"2021-09-28T06:50:59.176276Z","shell.execute_reply":"2021-09-28T06:50:59.176299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Facial Recognition","metadata":{"id":"Aswkw4k5aHvX"}},{"cell_type":"code","source":"import dlib\n\nfrontalface_detector = dlib.get_frontal_face_detector()\ndef rect_to_bb(rect):\n    x = rect.left()\n    y = rect.top()\n    w = rect.right() - x\n    h = rect.bottom() - y\n    return (x, y, w, h)\n    \ndef detect_face(image_url):\n    try:\n        url_response = urllib.request.urlopen(image_url)\n        img_array = np.array(bytearray(url_response.read()), dtype=np.uint8)\n        image = cv2.imdecode(img_array, -1)\nrects = frontalface_detector(image, 1)\nif len(rects) < 1:\n    return \"No Face Detected\"\nfor (i, rect) in enumerate(rects):\n    (x, y, w, h) = rect_to_bb(rect)\n    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\nplt.imshow(image, interpolation='nearest')\nplt.axis('off')\nplt.show()","metadata":{"id":"CL5sRPQzaGU0","execution":{"iopub.status.busy":"2021-09-28T06:50:59.177550Z","iopub.status.idle":"2021-09-28T06:50:59.178096Z","shell.execute_reply.started":"2021-09-28T06:50:59.177848Z","shell.execute_reply":"2021-09-28T06:50:59.177871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frontalface_detector = dlib.get_frontal_face_detector()\nlandmark_predictor=dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')\ndef get_landmarks(image_url):\n    try:\n        url_response = urllib.request.urlopen(image_url)\n        img_array = np.array(bytearray(url_response.read()), dtype=np.uint8)\n        image = cv2.imdecode(img_array, -1)\n    except Exception as e:\n        print (\"Please check the URL and try again!\")\n        return None,None\n    faces = frontalface_detector(image, 1)\n    if len(faces):\n        landmarks = [(p.x, p.y) for p in landmark_predictor(image, faces[0]).parts()]\n    else:\n        return None,None\n    \n    return image,landmarks\ndef image_landmarks(image,face_landmarks):\n    radius = -1\n    circle_thickness = 4\n    image_copy = image.copy()\n    for (x, y) in face_landmarks:\n        cv2.circle(image_copy, (x, y), circle_thickness, (255,0,0), radius)\n        plt.imshow(image_copy, interpolation='nearest')\n        plt.axis('off')\n        plt.show()","metadata":{"id":"ciHaxE75aRzM","execution":{"iopub.status.busy":"2021-09-28T06:50:59.179571Z","iopub.status.idle":"2021-09-28T06:50:59.180398Z","shell.execute_reply.started":"2021-09-28T06:50:59.180134Z","shell.execute_reply":"2021-09-28T06:50:59.180172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Represent Model as JSON String","metadata":{"id":"JiYFCxS2Qpwr"}},{"cell_type":"code","source":"model_json = model.to_json()\n\nwith open('model.json', 'w') as json_file:\n    json_file.write(model_json)","metadata":{"id":"cHw8ir7CVAE0","execution":{"iopub.status.busy":"2021-09-28T06:50:59.181439Z","iopub.status.idle":"2021-09-28T06:50:59.182145Z","shell.execute_reply.started":"2021-09-28T06:50:59.181906Z","shell.execute_reply":"2021-09-28T06:50:59.181930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"LLkv8MqFQpws"},"execution_count":null,"outputs":[]}]}