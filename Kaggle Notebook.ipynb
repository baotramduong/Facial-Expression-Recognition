{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nimport cv2\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, plot_confusion_matrix\nfrom sklearn.metrics import auc,roc_curve,roc_auc_score\n\nimport tensorflow as tf\nprint(\"Tensorflow version:\", tf.__version__)\n\n!pip install git+https://github.com/tensorflow/docs\nimport tensorflow_docs as tfdocs\nimport tensorflow_docs.modeling\n\nimport tensorflow.keras as keras\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, array_to_img, img_to_array\nfrom tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\nfrom tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.utils import plot_model\n\nfrom IPython.display import SVG, Image\n\n!pip install livelossplot\nfrom livelossplot.tf_keras import PlotLossesCallback\n\nimport warnings\nwarnings.filterwarnings(action='ignore', category=FutureWarning)","metadata":{"id":"wvGxjjeV-9Ls","outputId":"3c873904-9ac3-471c-81a8-bcf71772cfc6","execution":{"iopub.status.busy":"2021-09-28T09:14:13.988637Z","iopub.execute_input":"2021-09-28T09:14:13.989262Z","iopub.status.idle":"2021-09-28T09:14:38.604069Z","shell.execute_reply.started":"2021-09-28T09:14:13.989219Z","shell.execute_reply":"2021-09-28T09:14:38.603214Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{"id":"Tg1p132CQpwl"}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename));","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:32.442554Z","iopub.status.idle":"2021-09-28T09:09:32.442979Z","shell.execute_reply.started":"2021-09-28T09:09:32.442750Z","shell.execute_reply":"2021-09-28T09:09:32.442773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define path to the data directory\nbase_dir = '/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/'","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:32.444445Z","iopub.status.idle":"2021-09-28T09:09:32.444859Z","shell.execute_reply.started":"2021-09-28T09:09:32.444637Z","shell.execute_reply":"2021-09-28T09:09:32.444658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(base_dir)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:32.446147Z","iopub.status.idle":"2021-09-28T09:09:32.446567Z","shell.execute_reply.started":"2021-09-28T09:09:32.446342Z","shell.execute_reply":"2021-09-28T09:09:32.446364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#read the entire dataset\ndf = pd.read_csv(base_dir+'icml_face_data.csv')\ndf.columns = ['emotion', 'Usage', 'pixels']\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:32.447823Z","iopub.status.idle":"2021-09-28T09:09:32.448242Z","shell.execute_reply.started":"2021-09-28T09:09:32.448010Z","shell.execute_reply":"2021-09-28T09:09:32.448031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:32.449670Z","iopub.status.idle":"2021-09-28T09:09:32.450083Z","shell.execute_reply.started":"2021-09-28T09:09:32.449856Z","shell.execute_reply":"2021-09-28T09:09:32.449879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['emotion'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:32.451376Z","iopub.status.idle":"2021-09-28T09:09:32.451786Z","shell.execute_reply.started":"2021-09-28T09:09:32.451566Z","shell.execute_reply":"2021-09-28T09:09:32.451586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Usage'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:32.453088Z","iopub.status.idle":"2021-09-28T09:09:32.453526Z","shell.execute_reply.started":"2021-09-28T09:09:32.453293Z","shell.execute_reply":"2021-09-28T09:09:32.453313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#read train data\ntrain = pd.read_csv(base_dir+'train.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:32.454814Z","iopub.status.idle":"2021-09-28T09:09:32.455437Z","shell.execute_reply.started":"2021-09-28T09:09:32.455193Z","shell.execute_reply":"2021-09-28T09:09:32.455216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#read test data\ntest = pd.read_csv(base_dir+'test.csv')\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:32.514541Z","iopub.execute_input":"2021-09-28T09:09:32.514741Z","iopub.status.idle":"2021-09-28T09:09:33.005151Z","shell.execute_reply.started":"2021-09-28T09:09:32.514718Z","shell.execute_reply":"2021-09-28T09:09:33.004303Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:33.006833Z","iopub.execute_input":"2021-09-28T09:09:33.007163Z","iopub.status.idle":"2021-09-28T09:09:33.011728Z","shell.execute_reply.started":"2021-09-28T09:09:33.007128Z","shell.execute_reply":"2021-09-28T09:09:33.010970Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(30,8))\n\nsns.countplot(data = df[df['Usage']=='Training'], x='emotion', ax=ax1, palette='Spectral').set_title('Training')\nax1.set_xticklabels(emotions.values())\n\nsns.countplot(data = df[df['Usage']=='PublicTest'], x='emotion', ax=ax2, palette='Spectral').set_title('Testing')\nax2.set_xticklabels(emotions.values())\n\nsns.countplot(data = df[df['Usage']=='PrivateTest'], x='emotion', ax=ax3, palette='Spectral').set_title('Validation')\nax3.set_xticklabels(emotions.values())","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:33.012940Z","iopub.execute_input":"2021-09-28T09:09:33.013675Z","iopub.status.idle":"2021-09-28T09:09:33.561244Z","shell.execute_reply.started":"2021-09-28T09:09:33.013638Z","shell.execute_reply":"2021-09-28T09:09:33.560455Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(1, (20, 20))\n\nk = 0\nfor label in sorted(df['emotion'].unique()):\n    for j in range(7):\n        px = df[df['emotion']==label].pixels.iloc[k]\n        px = np.array(px.split(' ')).reshape(48, 48).astype('float32')\n\n        k += 1\n        ax = plt.subplot(7, 7, k)\n        ax.imshow(px, cmap='gray')\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(emotions[label])\n        plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:33.562629Z","iopub.execute_input":"2021-09-28T09:09:33.563098Z","iopub.status.idle":"2021-09-28T09:09:41.320684Z","shell.execute_reply.started":"2021-09-28T09:09:33.563055Z","shell.execute_reply":"2021-09-28T09:09:41.319997Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"## Prepare Train & Test Set Inputs\n### Train Set","metadata":{}},{"cell_type":"code","source":"train_data = df[df['Usage']=='Training']\ntrain_data.drop(columns='Usage', inplace=True)\ntrain_data.head()","metadata":{"id":"D3RHxw7nQpwm","execution":{"iopub.status.busy":"2021-09-28T09:09:41.323218Z","iopub.execute_input":"2021-09-28T09:09:41.323529Z","iopub.status.idle":"2021-09-28T09:09:41.344920Z","shell.execute_reply.started":"2021-09-28T09:09:41.323493Z","shell.execute_reply":"2021-09-28T09:09:41.344067Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"train_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:41.346457Z","iopub.execute_input":"2021-09-28T09:09:41.346717Z","iopub.status.idle":"2021-09-28T09:09:41.360081Z","shell.execute_reply.started":"2021-09-28T09:09:41.346683Z","shell.execute_reply":"2021-09-28T09:09:41.357791Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:41.361157Z","iopub.execute_input":"2021-09-28T09:09:41.361392Z","iopub.status.idle":"2021-09-28T09:09:41.383322Z","shell.execute_reply.started":"2021-09-28T09:09:41.361361Z","shell.execute_reply":"2021-09-28T09:09:41.382624Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"train_data['pixels'][0]","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:41.384754Z","iopub.execute_input":"2021-09-28T09:09:41.385316Z","iopub.status.idle":"2021-09-28T09:09:41.393560Z","shell.execute_reply.started":"2021-09-28T09:09:41.385268Z","shell.execute_reply":"2021-09-28T09:09:41.391606Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"def prepare_data(data):\n    image_array = np.zeros(shape=(len(data), 48, 48, 1))\n    image_label = np.array(list(map(int, data['emotion'])))\n\n    for i, row in enumerate(data.index):\n        image = np.fromstring(data.loc[row, 'pixels'], dtype=int, sep=' ')\n        image = np.reshape(image, (48, 48)) \n        image_array[i, :, :, 0] = image / 255\n\n    return image_array, image_label","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:41.395626Z","iopub.execute_input":"2021-09-28T09:09:41.396079Z","iopub.status.idle":"2021-09-28T09:09:41.407098Z","shell.execute_reply.started":"2021-09-28T09:09:41.396045Z","shell.execute_reply":"2021-09-28T09:09:41.406374Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = prepare_data(train_data)\nprint(X_train.shape, y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:41.408677Z","iopub.execute_input":"2021-09-28T09:09:41.409172Z","iopub.status.idle":"2021-09-28T09:09:45.198522Z","shell.execute_reply.started":"2021-09-28T09:09:41.409136Z","shell.execute_reply":"2021-09-28T09:09:45.196954Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:45.199975Z","iopub.execute_input":"2021-09-28T09:09:45.200251Z","iopub.status.idle":"2021-09-28T09:09:45.212438Z","shell.execute_reply.started":"2021-09-28T09:09:45.200215Z","shell.execute_reply":"2021-09-28T09:09:45.211532Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:45.213972Z","iopub.execute_input":"2021-09-28T09:09:45.214469Z","iopub.status.idle":"2021-09-28T09:09:45.221728Z","shell.execute_reply.started":"2021-09-28T09:09:45.214429Z","shell.execute_reply":"2021-09-28T09:09:45.220795Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"### Test Set","metadata":{}},{"cell_type":"code","source":"test_data = df[df['Usage']!='Training']\ntest_data.drop(columns='Usage', inplace=True)\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:45.223255Z","iopub.execute_input":"2021-09-28T09:09:45.223572Z","iopub.status.idle":"2021-09-28T09:09:45.244938Z","shell.execute_reply.started":"2021-09-28T09:09:45.223523Z","shell.execute_reply":"2021-09-28T09:09:45.244101Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"X_test, y_test = prepare_data(test_data)\nprint(X_test.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:45.248985Z","iopub.execute_input":"2021-09-28T09:09:45.249208Z","iopub.status.idle":"2021-09-28T09:09:46.075405Z","shell.execute_reply.started":"2021-09-28T09:09:45.249178Z","shell.execute_reply":"2021-09-28T09:09:46.074621Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"print('X_train', X_train.shape)\nprint('X_test', X_test.shape)\n\nprint('y_train', y_train.shape)\nprint('y_test', y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:46.076587Z","iopub.execute_input":"2021-09-28T09:09:46.077268Z","iopub.status.idle":"2021-09-28T09:09:46.084644Z","shell.execute_reply.started":"2021-09-28T09:09:46.077228Z","shell.execute_reply":"2021-09-28T09:09:46.083764Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"### Train Test Split","metadata":{}},{"cell_type":"code","source":"#train val split\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n                                                  shuffle=True, \n                                                  stratify=y_train,\n                                                  test_size=0.2, \n                                                  random_state=121)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:46.085923Z","iopub.execute_input":"2021-09-28T09:09:46.086406Z","iopub.status.idle":"2021-09-28T09:09:46.272678Z","shell.execute_reply.started":"2021-09-28T09:09:46.086350Z","shell.execute_reply":"2021-09-28T09:09:46.271877Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"markdown","source":"### Prepare Labels","metadata":{}},{"cell_type":"code","source":"#encode labels\nle = LabelEncoder()\ny_train = le.fit_transform(y_train)\ny_train = keras.utils.to_categorical(y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:46.274081Z","iopub.execute_input":"2021-09-28T09:09:46.274360Z","iopub.status.idle":"2021-09-28T09:09:46.280862Z","shell.execute_reply.started":"2021-09-28T09:09:46.274324Z","shell.execute_reply":"2021-09-28T09:09:46.279908Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"#ecode labels\ny_test = le.transform(y_test)\ny_test = keras.utils.to_categorical(y_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:46.282394Z","iopub.execute_input":"2021-09-28T09:09:46.282687Z","iopub.status.idle":"2021-09-28T09:09:46.289494Z","shell.execute_reply.started":"2021-09-28T09:09:46.282651Z","shell.execute_reply":"2021-09-28T09:09:46.288651Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"#ecode labels\ny_val = le.transform(y_val)\ny_val = keras.utils.to_categorical(y_val)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:46.291030Z","iopub.execute_input":"2021-09-28T09:09:46.291430Z","iopub.status.idle":"2021-09-28T09:09:46.298138Z","shell.execute_reply.started":"2021-09-28T09:09:46.291398Z","shell.execute_reply":"2021-09-28T09:09:46.297377Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"print('y_train', y_train.shape)\nprint('y_test', y_test.shape)\nprint('y_val', y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:46.299198Z","iopub.execute_input":"2021-09-28T09:09:46.299738Z","iopub.status.idle":"2021-09-28T09:09:46.308149Z","shell.execute_reply.started":"2021-09-28T09:09:46.299703Z","shell.execute_reply":"2021-09-28T09:09:46.307461Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:46.309524Z","iopub.execute_input":"2021-09-28T09:09:46.309866Z","iopub.status.idle":"2021-09-28T09:09:46.317762Z","shell.execute_reply.started":"2021-09-28T09:09:46.309800Z","shell.execute_reply":"2021-09-28T09:09:46.316528Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"y_test","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:46.319653Z","iopub.execute_input":"2021-09-28T09:09:46.320033Z","iopub.status.idle":"2021-09-28T09:09:46.329095Z","shell.execute_reply.started":"2021-09-28T09:09:46.319993Z","shell.execute_reply":"2021-09-28T09:09:46.328236Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"def plot_examples(label):\n    fig, axs = plt.subplots(1, 5, figsize=(20, 8))\n    fig.subplots_adjust(hspace = .2, wspace=.2)\n    axs = axs.ravel()\n    for i in range(5):\n        idx = train_data[train_data['emotion']==label].index[i]\n        axs[i].imshow(X_train[idx][:,:,0], cmap='gray')\n        axs[i].set_title(emotions[label])\n        axs[i].set_xticklabels([])\n        axs[i].set_yticklabels([])","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:46.330665Z","iopub.execute_input":"2021-09-28T09:09:46.331138Z","iopub.status.idle":"2021-09-28T09:09:46.340043Z","shell.execute_reply.started":"2021-09-28T09:09:46.331091Z","shell.execute_reply":"2021-09-28T09:09:46.339026Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"plot_examples(label=0)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:46.341521Z","iopub.execute_input":"2021-09-28T09:09:46.341919Z","iopub.status.idle":"2021-09-28T09:09:46.870662Z","shell.execute_reply.started":"2021-09-28T09:09:46.341883Z","shell.execute_reply":"2021-09-28T09:09:46.869985Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"plot_examples(label=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:46.871882Z","iopub.execute_input":"2021-09-28T09:09:46.872647Z","iopub.status.idle":"2021-09-28T09:09:47.396207Z","shell.execute_reply.started":"2021-09-28T09:09:46.872607Z","shell.execute_reply":"2021-09-28T09:09:47.395494Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"plot_examples(label=2)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:47.397496Z","iopub.execute_input":"2021-09-28T09:09:47.397862Z","iopub.status.idle":"2021-09-28T09:09:47.931356Z","shell.execute_reply.started":"2021-09-28T09:09:47.397821Z","shell.execute_reply":"2021-09-28T09:09:47.930648Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"plot_examples(label=3)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:47.932742Z","iopub.execute_input":"2021-09-28T09:09:47.932986Z","iopub.status.idle":"2021-09-28T09:09:48.466241Z","shell.execute_reply.started":"2021-09-28T09:09:47.932953Z","shell.execute_reply":"2021-09-28T09:09:48.465507Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"plot_examples(label=4)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:48.467469Z","iopub.execute_input":"2021-09-28T09:09:48.467807Z","iopub.status.idle":"2021-09-28T09:09:48.986765Z","shell.execute_reply.started":"2021-09-28T09:09:48.467770Z","shell.execute_reply":"2021-09-28T09:09:48.986084Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"plot_examples(label=5)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:48.987953Z","iopub.execute_input":"2021-09-28T09:09:48.988430Z","iopub.status.idle":"2021-09-28T09:09:49.585818Z","shell.execute_reply.started":"2021-09-28T09:09:48.988391Z","shell.execute_reply":"2021-09-28T09:09:49.584881Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"plot_examples(label=6)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:09:49.587519Z","iopub.execute_input":"2021-09-28T09:09:49.587792Z","iopub.status.idle":"2021-09-28T09:09:50.286709Z","shell.execute_reply.started":"2021-09-28T09:09:49.587752Z","shell.execute_reply":"2021-09-28T09:09:50.286028Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"markdown","source":"## Data Loader and Data Augmentation","metadata":{"id":"6OGl90WwQpwm"}},{"cell_type":"code","source":"img_size = 48\nbatch_size = 32\n\n#use Image Data Generator to perform this task\n#train set\ndatagen = ImageDataGenerator(rotation_range=25, \n                             width_shift_range=0.1,\n                             height_shift_range=0.1, \n                             shear_range=0.2, \n                             zoom_range=0.2,\n                             horizontal_flip=True)\n\ndatagen.fit(X_train)\ndatagen.fit(X_val)","metadata":{"id":"eiLYEHfuWt4N","execution":{"iopub.status.busy":"2021-09-28T09:09:50.287950Z","iopub.execute_input":"2021-09-28T09:09:50.288277Z","iopub.status.idle":"2021-09-28T09:09:50.499941Z","shell.execute_reply.started":"2021-09-28T09:09:50.288240Z","shell.execute_reply":"2021-09-28T09:09:50.499194Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"markdown","source":"## Build Model","metadata":{"id":"qxPfLAs-Qpwo"}},{"cell_type":"code","source":"model = Sequential()\n\n#1st conv\nmodel.add(Conv2D(64, (3,3), padding='same', input_shape=(48,48,1))) #1 is for grayscale\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#2nd conv\nmodel.add(Conv2D(128, (5,5), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#3rd conv\nmodel.add(Conv2D(512, (3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#4th conv\nmodel.add(Conv2D(512, (3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(7, activation='softmax'))","metadata":{"id":"uVJJqiPbQpwo","execution":{"iopub.status.busy":"2021-09-28T09:09:50.501407Z","iopub.execute_input":"2021-09-28T09:09:50.501685Z","iopub.status.idle":"2021-09-28T09:09:50.682276Z","shell.execute_reply.started":"2021-09-28T09:09:50.501651Z","shell.execute_reply":"2021-09-28T09:09:50.681523Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"#compile\nmodel.compile(optimizer=keras.optimizers.Adam(learning_rate = 1e-5),\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])","metadata":{"id":"isuc5IcUQpwp","execution":{"iopub.status.busy":"2021-09-28T09:09:50.683705Z","iopub.execute_input":"2021-09-28T09:09:50.683949Z","iopub.status.idle":"2021-09-28T09:09:50.697027Z","shell.execute_reply.started":"2021-09-28T09:09:50.683917Z","shell.execute_reply":"2021-09-28T09:09:50.695943Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"id":"PB1zZcr6Qpwq","execution":{"iopub.status.busy":"2021-09-28T09:09:50.698757Z","iopub.execute_input":"2021-09-28T09:09:50.699161Z","iopub.status.idle":"2021-09-28T09:09:50.722558Z","shell.execute_reply.started":"2021-09-28T09:09:50.699106Z","shell.execute_reply":"2021-09-28T09:09:50.721818Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\n\n#plot\nplot_model(model, to_file = 'model_plot.png', show_shapes = True, show_layer_names = True)","metadata":{"id":"lY8ghrg7YHZ0","execution":{"iopub.status.busy":"2021-09-28T09:09:50.723751Z","iopub.execute_input":"2021-09-28T09:09:50.725362Z","iopub.status.idle":"2021-09-28T09:09:51.138699Z","shell.execute_reply.started":"2021-09-28T09:09:50.725331Z","shell.execute_reply":"2021-09-28T09:09:51.137771Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"markdown","source":"## Train Model","metadata":{"id":"WSpOKdKsQpwq"}},{"cell_type":"code","source":"epochs = 3\n\n#checkpoint to save best weights\ncheckpoint = ModelCheckpoint('model_weights.h5',\n                             monitor='val_accuracy',\n                             save_weights_only=True,\n                             mode='max')\n\n#reduce learning rate if plateau\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.1,\n                              patience=2,\n                              min_lr=0.00001,\n                              mode='min')\n\n#stop training if accuracy does not improve\nearlystop = EarlyStopping(monitor='val_accuracy',\n                          patience=5,\n                          mode='max')\n\n#define callbacks\ncallbacks = [tfdocs.modeling.EpochDots(), \n             earlystop, \n             checkpoint, \n             reduce_lr]","metadata":{"id":"N2vaREgMQpwq","execution":{"iopub.status.busy":"2021-09-28T09:16:48.625061Z","iopub.execute_input":"2021-09-28T09:16:48.625621Z","iopub.status.idle":"2021-09-28T09:16:48.631144Z","shell.execute_reply.started":"2021-09-28T09:16:48.625586Z","shell.execute_reply":"2021-09-28T09:16:48.630428Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"%%time\n\nhistory = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n                    validation_data=(X_val, y_val),\n                    steps_per_epoch=len(X_train) / batch_size,\n                    epochs=epochs,\n                    callbacks=callbacks,\n                    verbose=0)","metadata":{"id":"aqZE_nD0Qpwr","execution":{"iopub.status.busy":"2021-09-28T09:17:59.150554Z","iopub.execute_input":"2021-09-28T09:17:59.150840Z","iopub.status.idle":"2021-09-28T09:18:34.755949Z","shell.execute_reply.started":"2021-09-28T09:17:59.150803Z","shell.execute_reply":"2021-09-28T09:18:34.755208Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate Model ","metadata":{"id":"aVrjqCeKQpwr"}},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\nfig.set_size_inches(20, 8)\n\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(train_acc) + 1)\n\nax[0].plot(epochs , train_acc , 'g-o' , label = 'Training Accuracy')\nax[0].plot(epochs , val_acc , 'y-o' , label = 'Validation Accuracy')\nax[0].set_title('Model Training & Validation Accuracy')\nax[0].legend(loc = 'lower right')\nax[0].set_xlabel(\"Epochs\")\nax[0].set_ylabel(\"Accuracy\")\n\nax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\nax[1].plot(epochs , val_loss , 'y-o' , label = 'Validation Loss')\nax[1].set_title('Model Training & Validation & Loss')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nax[1].set_ylabel(\"Loss\")\n\nplt.show()","metadata":{"id":"2aF_3ka3V4Pt","execution":{"iopub.status.busy":"2021-09-28T09:09:51.183964Z","iopub.status.idle":"2021-09-28T09:09:51.184398Z","shell.execute_reply.started":"2021-09-28T09:09:51.184165Z","shell.execute_reply":"2021-09-28T09:09:51.184186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train accuracy & loss:', model.evaluate(X_train, y_train))\nprint('\\n')\nprint('Test accuracy & loss:', model.evaluate(X_test, y_test))","metadata":{"id":"UbROrWHOV7IH","execution":{"iopub.status.busy":"2021-09-28T09:19:00.786853Z","iopub.execute_input":"2021-09-28T09:19:00.787130Z","iopub.status.idle":"2021-09-28T09:19:05.472568Z","shell.execute_reply.started":"2021-09-28T09:19:00.787088Z","shell.execute_reply":"2021-09-28T09:19:05.471777Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"#make prediction\nyhat_test = np.argmax(model.predict(X_test), axis=1)\nyhat_test","metadata":{"id":"bbGgOWUgV9Uv","execution":{"iopub.status.busy":"2021-09-28T09:19:21.219188Z","iopub.execute_input":"2021-09-28T09:19:21.219631Z","iopub.status.idle":"2021-09-28T09:19:21.987815Z","shell.execute_reply.started":"2021-09-28T09:19:21.219596Z","shell.execute_reply":"2021-09-28T09:19:21.986465Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"y_test = np.argmax(y_test, axis=1)\ny_test","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:19:28.643066Z","iopub.execute_input":"2021-09-28T09:19:28.643349Z","iopub.status.idle":"2021-09-28T09:19:28.650094Z","shell.execute_reply.started":"2021-09-28T09:19:28.643320Z","shell.execute_reply":"2021-09-28T09:19:28.649202Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"from mlxtend.plotting import plot_confusion_matrix\n\n#get confusion matrix\ncm = confusion_matrix(y_test, yhat_test)\nprint(cm)\n\nfig, ax = plot_confusion_matrix(conf_mat=cm,\n                                show_normed=True,\n                                show_absolute=False,\n                                class_names=emotions.values(),\n                                figsize=(8, 8))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:19:29.435971Z","iopub.execute_input":"2021-09-28T09:19:29.436698Z","iopub.status.idle":"2021-09-28T09:19:29.811722Z","shell.execute_reply.started":"2021-09-28T09:19:29.436658Z","shell.execute_reply":"2021-09-28T09:19:29.811058Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"#get classification report\nprint(classification_report(y_test, yhat_test, target_names=emotions.values()))","metadata":{"id":"CySOfMCdWUk2","execution":{"iopub.status.busy":"2021-09-28T09:19:35.068801Z","iopub.execute_input":"2021-09-28T09:19:35.069096Z","iopub.status.idle":"2021-09-28T09:19:35.091927Z","shell.execute_reply.started":"2021-09-28T09:19:35.069064Z","shell.execute_reply":"2021-09-28T09:19:35.091222Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"model_json = model.to_json()\nwith open('model.json','w') as json_file:\n    json_file.write(model_json)\n    \nmodel.save('final_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:19:35.429589Z","iopub.execute_input":"2021-09-28T09:19:35.430164Z","iopub.status.idle":"2021-09-28T09:19:35.613568Z","shell.execute_reply.started":"2021-09-28T09:19:35.430109Z","shell.execute_reply":"2021-09-28T09:19:35.612677Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"markdown","source":"## Make Prediction","metadata":{"id":"5a3ddKtGa_fy"}},{"cell_type":"code","source":"plt.figure(figsize=[16,16])\nfor i in range(36):\n    img = X_test[i,:,:,0]\n    p_dist = model.predict(img.reshape(1,48,48,1))\n    k = np.argmax(p_dist)\n    p = np.max(p_dist)\n\n    #cam = GradCAM(model, k)\n    #heatmap = cam.compute_heatmap(img.reshape(1,48,48,1))\n\n    plt.subplot(6,6,i+1)\n    plt.imshow(img, cmap='binary_r')\n    #plt.imshow(heatmap, alpha=0.5, cmap='RdBu_r')\n    plt.title(f'{emotions[y_test[i]]} - ({emotions[k]} - {p:.4f})')\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:58:26.917644Z","iopub.execute_input":"2021-09-28T09:58:26.917949Z","iopub.status.idle":"2021-09-28T09:58:30.330690Z","shell.execute_reply.started":"2021-09-28T09:58:26.917917Z","shell.execute_reply":"2021-09-28T09:58:30.330018Z"},"trusted":true},"execution_count":171,"outputs":[]},{"cell_type":"markdown","source":"## VizGradCAM","metadata":{"id":"yk4p_LpXZEGd"}},{"cell_type":"code","source":"#https://github.com/gkeechin/vizgradcam/blob/main/gradcam.py\n\ndef VizGradCAM(model, image, interpolant=0.5, plot_results=True):\n\n    \"\"\"VizGradCAM - Displays GradCAM based on Keras / TensorFlow models\n    using the gradients from the last convolutional layer. This function\n    should work with all Keras Application listed here:\n    https://keras.io/api/applications/\n    Parameters:\n    model (keras.model): Compiled Model with Weights Loaded\n    image: Image to Perform Inference On\n    plot_results (boolean): True - Function Plots using PLT\n                            False - Returns Heatmap Array\n    Returns:\n    Heatmap Array?\n    \"\"\"\n    #sanity check\n    assert (interpolant > 0 and interpolant < 1), \"Heatmap Interpolation Must Be Between 0 - 1\"\n\n    #STEP 1: Preprocesss image and make prediction using our model\n    #input image\n    original_img = np.asarray(image, dtype = np.float32)\n    #expamd dimension and get batch size\n    img = np.expand_dims(original_img, axis=0)\n    #predict\n    prediction = model.predict(img)\n    #prediction index\n    prediction_idx = np.argmax(prediction)\n\n    #STEP 2: Create new model\n    #specify last convolutional layer\n    last_conv_layer = next(x for x in model.layers[::-1] if isinstance(x, keras.layers.Conv2D))\n    target_layer = model.get_layer(last_conv_layer.name)\n\n    #compute gradient of top predicted class\n    with tf.GradientTape() as tape:\n        #create a model with original model inputs and the last conv_layer as the output\n        gradient_model = Model([model.inputs], [target_layer.output, model.output])\n        #pass the image through the base model and get the feature map  \n        conv2d_out, prediction = gradient_model(img)\n        #prediction loss\n        loss = prediction[:, prediction_idx]\n\n    #gradient() computes the gradient using operations recorded in context of this tape\n    gradients = tape.gradient(loss, conv2d_out)\n\n    #obtain the output from shape [1 x H x W x CHANNEL] -> [H x W x CHANNEL]\n    output = conv2d_out[0]\n\n    #obtain depthwise mean\n    weights = tf.reduce_mean(gradients[0], axis=(0, 1))\n\n\n    #create a 7x7 map for aggregation\n    activation_map = np.zeros(output.shape[0:2], dtype=np.float32)\n    #multiply weight for every layer\n    for idx, weight in enumerate(weights):\n        activation_map += weight * output[:, :, idx]\n    #resize to image size\n    activation_map = cv2.resize(activation_map.numpy(), \n                                (original_img.shape[1], \n                                 original_img.shape[0]))\n    #ensure no negative number\n    activation_map = np.maximum(activation_map, 0)\n    #convert class activation map to 0 - 255\n    activation_map = (activation_map - activation_map.min()) / (activation_map.max() - activation_map.min())\n    #rescale and convert the type to int\n    activation_map = np.uint8(255 * activation_map)\n\n\n    #convert to heatmap\n    heatmap = cv2.applyColorMap(activation_map, cv2.COLORMAP_JET)\n\n    #superimpose heatmap onto image\n    original_img = np.uint8((original_img - original_img.min()) / (original_img.max() - original_img.min()) * 255)\n    cvt_heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n    cvt_heatmap = img_to_array(cvt_heatmap)\n\n    #enlarge plot\n    plt.rcParams[\"figure.dpi\"] = 100\n\n    if plot_results == True:\n        plt.imshow(np.uint8(original_img * interpolant + cvt_heatmap * (1 - interpolant)))\n    else:\n        return cvt_heatmap","metadata":{"id":"A2iJNT8GZCib","execution":{"iopub.status.busy":"2021-09-28T09:53:16.662362Z","iopub.execute_input":"2021-09-28T09:53:16.662692Z","iopub.status.idle":"2021-09-28T09:53:16.690619Z","shell.execute_reply.started":"2021-09-28T09:53:16.662654Z","shell.execute_reply":"2021-09-28T09:53:16.689726Z"},"trusted":true},"execution_count":165,"outputs":[]},{"cell_type":"code","source":"#load image\nn = 21\nimg = X_test[n,:,:,0]\n\n#apply function\nVizGradCAM(model, img_to_array(img), plot_results=True)","metadata":{"id":"5ZvQ17oRZHkO","execution":{"iopub.status.busy":"2021-09-28T09:53:29.265745Z","iopub.execute_input":"2021-09-28T09:53:29.266015Z","iopub.status.idle":"2021-09-28T09:53:29.634878Z","shell.execute_reply.started":"2021-09-28T09:53:29.265988Z","shell.execute_reply":"2021-09-28T09:53:29.634160Z"},"trusted":true},"execution_count":167,"outputs":[]},{"cell_type":"markdown","source":"## Grad-CAM","metadata":{}},{"cell_type":"code","source":"class GradCAM:\n    def __init__(self, model, classIdx, layerName=None):\n        self.model = model\n        self.classIdx = classIdx\n        self.layerName = layerName\n        if self.layerName is None:\n            self.layerName = self.find_target_layer()\n            \n    def find_target_layer(self):\n        for layer in reversed(self.model.layers):\n            if len(layer.output_shape) == 4:\n                return layer.name\n        raise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\n        \n    def compute_heatmap(self, image, eps=1e-8):\n        gradModel = Model(\n            inputs=[self.model.inputs],\n            outputs=[self.model.get_layer(self.layerName).output,self.model.output]\n       )\n           \n        with tf.GradientTape() as tape:\n            inputs = tf.cast(image, tf.float32)\n            (convOutputs, predictions) = gradModel(inputs)\n            loss = predictions[:, self.classIdx]\n            grads = tape.gradient(loss, convOutputs)\n\n            castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n            castGrads = tf.cast(grads > 0, \"float32\")\n            guidedGrads = castConvOutputs * castGrads * grads\n            convOutputs = convOutputs[0]\n            guidedGrads = guidedGrads[0]\n\n            weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n            cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n\n            (w, h) = (image.shape[2], image.shape[1])\n            heatmap = cv2.resize(cam.numpy(), (w, h))\n            numer = heatmap - np.min(heatmap)\n            denom = (heatmap.max() - heatmap.min()) + eps\n            heatmap = numer / denom\n            heatmap = (heatmap * 255).astype(\"uint8\")\n        return heatmap\n\n    def overlay_heatmap(self, heatmap, image, alpha=0.5,\n        colormap = cv2.COLORMAP_VIRIDIS):\n        heatmap = cv2.applyColorMap(heatmap, colormap)\n        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n        return (heatmap, output)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:28:01.432274Z","iopub.execute_input":"2021-09-28T09:28:01.433514Z","iopub.status.idle":"2021-09-28T09:28:01.584259Z","shell.execute_reply.started":"2021-09-28T09:28:01.433476Z","shell.execute_reply":"2021-09-28T09:28:01.583498Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=[16,16])\nfor i in range(36):\n    img = X_test[i,:,:,0]\n    p_dist = model.predict(img.reshape(1,48,48,1))\n    k = np.argmax(p_dist)\n    p = np.max(p_dist)\n\n    cam = GradCAM(model, k)\n    heatmap = cam.compute_heatmap(img.reshape(1,48,48,1))\n\n    plt.subplot(6,6,i+1)\n    plt.imshow(img, cmap='binary_r')\n    plt.imshow(heatmap, alpha=0.5, cmap='RdBu_r')\n    plt.title(f'{emotions[y_test[i]]} - ({emotions[k]} - {p:.4f})')\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:52:20.076534Z","iopub.execute_input":"2021-09-28T09:52:20.076804Z","iopub.status.idle":"2021-09-28T09:52:24.975914Z","shell.execute_reply.started":"2021-09-28T09:52:20.076776Z","shell.execute_reply":"2021-09-28T09:52:24.975049Z"},"trusted":true},"execution_count":164,"outputs":[]},{"cell_type":"code","source":"test_prob = model.predict(X_test)\ntest_pred = np.argmax(test_prob, axis=1)\n\nsel_imgs = [10, 15, 26, 12, 64, 14, 9]\n\nfor n in sel_imgs:\n    img = X_test[n,:,:,0]\n    \n    plt.figure(figsize=[10,3])\n    plt.subplot(1, 3, 1)\n    plt.imshow(img, cmap='binary_r')\n    plt.title(f'True Label: {emotions[y_test[n]]}')\n    plt.axis('off')\n    \n    cam = GradCAM(model, test_pred[n])\n    heatmap = cam.compute_heatmap(img.reshape(1,48,48,1))\n    \n    plt.subplot(1, 3, 2)\n    plt.imshow(img, cmap='binary_r')\n    plt.imshow(heatmap, alpha=0.5, cmap='RdBu_r')\n    plt.title(f'Predicted Label: {emotions[test_pred[n]]}')\n    plt.axis('off')\n    \n    plt.subplot(1, 3, 3)\n    plt.bar(emotions.values(), test_prob[n, :], color='steelblue', edgecolor='k')\n    plt.xticks(rotation=45)\n    plt.ylim([0,1])\n    plt.title('Distribution of Predictions')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T09:54:57.994529Z","iopub.execute_input":"2021-09-28T09:54:57.994790Z","iopub.status.idle":"2021-09-28T09:55:00.783450Z","shell.execute_reply.started":"2021-09-28T09:54:57.994761Z","shell.execute_reply":"2021-09-28T09:55:00.782743Z"},"trusted":true},"execution_count":170,"outputs":[]},{"cell_type":"markdown","source":"## Facial Recognition","metadata":{"id":"Aswkw4k5aHvX"}},{"cell_type":"code","source":"import dlib\n\nfrontalface_detector = dlib.get_frontal_face_detector()\ndef rect_to_bb(rect):\n    x = rect.left()\n    y = rect.top()\n    w = rect.right() - x\n    h = rect.bottom() - y\n    return (x, y, w, h)\n    \ndef detect_face(image_url):\n    try:\n        url_response = urllib.request.urlopen(image_url)\n        img_array = np.array(bytearray(url_response.read()), dtype=np.uint8)\n        image = cv2.imdecode(img_array, -1)\nrects = frontalface_detector(image, 1)\nif len(rects) < 1:\n    return \"No Face Detected\"\nfor (i, rect) in enumerate(rects):\n    (x, y, w, h) = rect_to_bb(rect)\n    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\nplt.imshow(image, interpolation='nearest')\nplt.axis('off')\nplt.show()","metadata":{"id":"CL5sRPQzaGU0","execution":{"iopub.status.busy":"2021-09-28T09:09:51.214438Z","iopub.status.idle":"2021-09-28T09:09:51.214916Z","shell.execute_reply.started":"2021-09-28T09:09:51.214652Z","shell.execute_reply":"2021-09-28T09:09:51.214676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frontalface_detector = dlib.get_frontal_face_detector()\nlandmark_predictor=dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')\ndef get_landmarks(image_url):\n    try:\n        url_response = urllib.request.urlopen(image_url)\n        img_array = np.array(bytearray(url_response.read()), dtype=np.uint8)\n        image = cv2.imdecode(img_array, -1)\n    except Exception as e:\n        print (\"Please check the URL and try again!\")\n        return None,None\n    faces = frontalface_detector(image, 1)\n    if len(faces):\n        landmarks = [(p.x, p.y) for p in landmark_predictor(image, faces[0]).parts()]\n    else:\n        return None,None\n    \n    return image,landmarks\n\ndef image_landmarks(image,face_landmarks):\n    radius = -1\n    circle_thickness = 4\n    image_copy = image.copy()\n    for (x, y) in face_landmarks:\n        cv2.circle(image_copy, (x, y), circle_thickness, (255,0,0), radius)\n        plt.imshow(image_copy, interpolation='nearest')\n        plt.axis('off')\n        plt.show()","metadata":{"id":"ciHaxE75aRzM","execution":{"iopub.status.busy":"2021-09-28T09:09:51.216497Z","iopub.status.idle":"2021-09-28T09:09:51.216902Z","shell.execute_reply.started":"2021-09-28T09:09:51.216682Z","shell.execute_reply":"2021-09-28T09:09:51.216703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Represent Model as JSON String","metadata":{"id":"JiYFCxS2Qpwr"}},{"cell_type":"code","source":"model_json = model.to_json()\n\nwith open('model.json', 'w') as json_file:\n    json_file.write(model_json)","metadata":{"id":"cHw8ir7CVAE0","execution":{"iopub.status.busy":"2021-09-28T09:09:51.218676Z","iopub.status.idle":"2021-09-28T09:09:51.219171Z","shell.execute_reply.started":"2021-09-28T09:09:51.218862Z","shell.execute_reply":"2021-09-28T09:09:51.218883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"LLkv8MqFQpws"},"execution_count":null,"outputs":[]}]}